\documentclass{homework}
\usepackage{gabri_notation}
\usepackage{tikz-qtree}

\course{15-888 Computational Game Solving (Fall 2023)}
\homework{1}
\releasedate{Sep. 18, 2023}
\duedate{Oct. 2, 2023, beginning of class}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\student{\todo{Your Andrew ID here}}

\newcommand{\negent}{\omega}

\begin{document}

\maketitle

\paragraph{Instructions} Please typeset your solution in the \texttt{.tex} file provided in the homework \texttt{.zip}. Attach a readable printout of your code at the end of the document. Turn in your printed solution at the beginning of class on October 2nd. Don't forget to fill in your student ID above.

\section{A Regret-Based Proof of the Minmax Theorem (30 points)}

Let $\cX \subseteq \bbR^n$ and $\cY \subseteq \bbR^m$ be convex and compact sets, and $\vec{A} \in \mathbb{R}^{n\times m}$. The minmax theorem asserts that
\[
    \max_{\vec{x}\in\cX}\min_{\vec{y}\in\cY} \vec{x}^\top\!\! \vec{A} \vec{y} = \min_{\vec{y}\in\cY}\max_{\vec{x}\in\cX} \vec{x}^\top\!\! \vec{A} \vec{y}.
\]
In this problem you will show that the fact that (external) regret minimization algorithms for
$\cX$ exist is a powerful enough statement to imply the minmax theorem.

One direction (called \emph{weak duality}) of the proof is easy and very general. Specifically, show the following.

\begin{problem}[8 points]
    Show that
    \[
        \max_{\vec{x}\in\cX}\min_{\vec{y}\in\cY} \vec{x}^\top\!\! \vec{A} \vec{y} \le \min_{\vec{y}\in\cY}\max_{\vec{x}\in\cX} \vec{x}^\top\!\! \vec{A} \vec{y}.
        \numberthis{eq:weak duality}
    \]
    \hint{start by arguing that for any $\vec{y}^*\in\cY$, $\max_{\vec{x}\in\cX}\min_{\vec{y}\in\cY} \vec{x}^\top\!\! \vec{A} \vec{y} \le \max_{\vec{x}\in\cX} \vec{x}^\top\!\! \vec{A} \vec{y}^* $.}
\end{problem}
\begin{solution}
    \todo{Your solution here}
\end{solution}


\noindent To show the reverse inequality, we will interpret the bilinear saddle point $\min_{\vec{y}\in\cY}\max_{\vec{x}\in\cX} \vec{x}^\top\!\! \vec{A} \vec{y}$ as a repeated game. At each time $t$, we will let a regret minimizer $\cR_\cX$ pick actions $\vec{x}^t \in\cX$, whereas we will always assume that $\vec{y}^t \in\cY$ is chosen by the environment to best respond to $\vec{x}^t$, that is,
\[
    \vec{y}^t \in \argmin_{\vec{y} \in \cY} (\vec{x}^t)^\top\!\! \vec{A} \vec{y}.
\]
The utility function observed by $\cR_\cX$ at each time $t$ is set to
\begin{equation*}
    \ell^t_\cX : \vec{x} \mapsto \vec{x}^\top\!\!\vec{A}\vec{y}^t = (\vec{A}\vec{y}^t)^\top \vec{x}.
\end{equation*}
By definition of regret minimizer, we will assume that $\cR_\cX$ guarantees \emph{sublinear regret} in the worst case.

Let $\bar{\vec{x}}^T \in \cX$ and $\bar{\vec{y}}^T \in \cY$ be the average strategies output up to time $T$, that is,
\[
    \bar{\vec{x}}^T \defeq \frac{1}{T}\sum_{t=1}^T \vec{x}^t \qquad \bar{\vec{y}}^T \defeq \frac{1}{T}\sum_{t=1}^T \vec{y}^t.
\] 

\begin{problem}[5 points]
    Argue that at all $t$,
    \[
        \max_{\vec{x}\in\cX}\min_{\vec{y}\in\cY} \vec{x}^\top\!\! \vec{A} \vec{y} \ge \frac{1}{T} \min_{\vec{y}\in\cY}\sum_{t=1}^T (\vec{x}^t)^\top\!\!\vec{A}\vec{y} \ge \frac{1}{T}\sum_{t=1}^T (\vec{x}^t)^\top\!\!\vec{A}\vec{y}^t.
        \numberthis{eq:minmax bound}
    \]
    \hint{lower bound the maximum over $\vec{x}\in\cX$ by plugging the particular choice $\bar{\vec{x}}^T$. Then, use the information you have on $\vec{y}^t$.}
\end{problem}
\begin{solution}
    \todo{Your solution here}
\end{solution}


\begin{problem}[5 points]
    Let $R_\cX^T$ be the regret accumulated by $\cR_\cX$ up to time $T$. Using~\eqref{eq:minmax bound}, argue that at all times $T$
    \[
        \max_{\vec{x}\in\cX}\min_{\vec{y}\in\cY} \vec{x}^\top\!\! \vec{A} \vec{y} \ge \min_{\vec{y}\in\cY}\max_{\vec{x}\in\cX} \vec{x}^\top\!\! \vec{A} \vec{y} - \frac{R^T_\cX}{T}.
        \numberthis{eq:minmax bound 2}
    \]
    \hint{use the definition of regret $R_\cX^T$.}
\end{problem}
\begin{solution}
    \todo{Your solution here}
\end{solution}


\begin{problem}[2 points]
    Use~\eqref{eq:minmax bound 2} and~\eqref{eq:weak duality} and to conclude that
    \[
        \max_{\vec{x}\in\cX}\min_{\vec{y}\in\cY} \vec{x}^\top\!\! \vec{A} \vec{y} = \min_{\vec{y}\in\cY}\max_{\vec{x}\in\cX} \vec{x}^\top\!\! \vec{A} \vec{y},
    \]
\end{problem}
\begin{solution}
    \todo{Your solution here}
\end{solution}


\section{Linear programming for solving zero-sum games, and application to low randomization in poker (70 points)}

In many games, the optimal Nash equilibrium requires that all players randomize their moves. As an example, consider rock-paper-scissors: any deterministic strategy (for example, always playing rock) is heavily suboptimal. In this problem, you will quantify how much value is lost by insisting on playing deterministic strategies in the three games of Homework~$1$: rock-paper-superscissors and two well-known poker variants---Kuhn poker~\citep{Kuhn50:Simplified} and Leduc poker~\citep{Southey05:Bayes}. A description of each game is given in the zip of this homework, according to the same format of Homework~$1$, recalled in \cref{sec:format}. The zip of the homework also contains a stub Python file to help you set up your implementation. 

\subsection{Format of the game files}\label{sec:format}

Each game is encoded as a json file with the following structure.
\begin{itemize}
    \item At the root, we have a dictionary with three keys: \verb|decision_problem_pl1|, \verb|decision_problem_pl2|, and \verb|utility_pl1|. The first two keys contain a description of the tree-form sequential decision problems faced by the two players, while the third is a description of the bilinear utility function for Player 1 as a function of the sequence-form strategies of each player. Since both games are zero-sum, the utility for Player 2 is the opposite of the utility of Player 1.
    \item The tree of decision points and observation points for each decision problem is stored as a list of nodes. Each node has the following fields
    \begin{description}
        \item[\texttt{id}] is a string that represents the identifier of the node. The identifier is unique among the nodes for the same player.
        \item[\texttt{type}] is a string with value either \verb|decision| (for decision points) or \verb|observation| (for observation points).
        \item[\texttt{actions}] (only for decision points). This is a set of strings, representing the actions available at the decision node.
        \item[\texttt{signals}] (only for observation points). This is a set of strings, representing the signals that can be observed at the observation node.
        \item[\texttt{parent\_edge}] identifies the parent edge of the node. If the node is the root of the tree, then it is \verb|null|. Else, it is a pair \verb|(parent_node_id, action_or_signal)|, where the first member is the \verb|id| of the parent node, and \verb|action_or_signal| is the action or signal that connects the node to its parent.
        \item[\texttt{parent\_sequence}] (only for decision points). Identifies the parent sequence $p_j$ of the decision point, defined as the last sequence (that is, decision point-action pair) encountered on the path from the root of the
        decision process to $j$.
    \end{description}
    \begin{remark}
        The list of nodes of the tree-form sequential decision process is given in top-down traversal order. The bottom-up traversal order can be obtained by reading the list of nodes backwards.
    \end{remark}
    \item The bilinear utility function for Player~1 is given through the payoff matrix $\vec{A}$ such that the (expected) utility of Player~1 can be written as
    \[
        u_1(\vec{x}, \vec{y}) = \vec{x}^\top\!\!\vec{A}\vec{y},
    \]
    where $\vec{x}$ and $\vec{y}$ are sequence-form strategies for Players~1 and 2 respectively. We represent $\vec{A}$ in the file as a list of all non-zero matrix entries, storing for each the row index, column index, and value. Specifically, each entry is an object with the fields
    \begin{description}
        \item[\texttt{sequence\_pl1}] is a pair \verb|(decision_pt_id_pl1, action_pl1)| which represents the sequence of Player~1 (row of the entry in the matrix).
        \item[\texttt{sequence\_pl2}] is a pair \verb|(decision_pt_id_pl2, action_pl2)| which represents the sequence of Player~2 (column of the entry in the matrix).
        \item[\texttt{value}] is the non-zero float value of the matrix entry. 
    \end{description}
\end{itemize}

\paragraph{Example: Rock-paper-superscissors}

In the case of rock-paper-superscissors the decision problem faced by each of the players has only one decision points with three actions: playing rock, paper, or superscissors. So, each tree-form sequential decision process only has a single node, which is a decision node. The payoff matrix of the game is
\begin{center}
    \begin{tikzpicture}
        \tikzset{every left delimiter/.style={xshift=1.5ex},
                every right delimiter/.style={xshift=-1ex}};
        \matrix [matrix of math nodes,left delimiter=(,right delimiter=),row sep=.008cm,column sep=.008cm,color=black](m)
        {
         0 & -1 &  1\\
         1 &  0 & -2\\
        -1 &  2 &  0\\
        };
        \node at (m-2-3 -| 1.4,0) {.};
        
        \node at (m-1-1 -| -1.5,0) {r};
        \node at (m-2-1 -| -1.5,0) {p};
        \node at (m-3-1 -| -1.5,0) {s};
        
        \node at (m-1-1 |- 0,1.0) {r};
        \node at (m-1-2 |- 0,1.0) {p};
        \node at (m-1-3 |- 0,1.0) {s};
    \end{tikzpicture}
\end{center}
So, the game file in this case has content:

{\small\begin{verbatim}
{
  "decision_problem_pl1": [
    {"id": "d1_pl1", "type": "decision", "actions": ["r", "p", "s"],
     "parent_edge": null, "parent_sequence": null}
  ],
  "decision_problem_pl2": [
    {"id": "d1_pl2", "type": "decision", "actions": ["r", "p", "s"],
     "parent_edge": null, "parent_sequence": null}
  ],
  "utility_pl1": [
    {"sequence_pl1": ["d1_pl1", "r"], "sequence_pl2": ["d1_pl2", "p"], "value": -1},
    {"sequence_pl1": ["d1_pl1", "r"], "sequence_pl2": ["d1_pl2", "s"], "value": 1},
    {"sequence_pl1": ["d1_pl1", "p"], "sequence_pl2": ["d1_pl2", "r"], "value": 1},
    {"sequence_pl1": ["d1_pl1", "p"], "sequence_pl2": ["d1_pl2", "s"], "value": -2},
    {"sequence_pl1": ["d1_pl1", "s"], "sequence_pl2": ["d1_pl2", "r"], "value": -1},
    {"sequence_pl1": ["d1_pl1", "s"], "sequence_pl2": ["d1_pl2", "p"], "value": 2}
  ]
}
\end{verbatim}}

\subsection{Computing the value of the game (20 points)}

As a warmup, you will implement the linear program formulation of Nash equilibrium strategies seen in Lecture~$10$ using the commercial solver Gurobi (\url{https://www.gurobi.com/}). Gurobi is a powerful commercial solver for linear and non-linear optimization problems. You can download the solver and request a free license for academic use from their website.

\paragraph{Installing \texttt{gurobipy}}
Installation instructions for Gurobi's python bindings are available on the Gurobi website, \href{https://www.gurobi.com/documentation/9.1/quickstart_linux/cs_python.html#section:Python}{here}.\footnote{\texttt{https://www.gurobi.com/documentation/9.1/quickstart\_linux/cs\_python.html\#section:Python}}

\paragraph{Linear programming formulation of Nash equilibrium strategies}
For your convenience, here are again the linear programs---for Player~$1$ and Player~$2$, respectively---that you need to implement:
\begin{equation}\label{eq:nash lp}
    \arraycolsep=1.0pt
    \mathcal{P}_1 : \mleft\lbrace\begin{array}{l}
        \displaystyle\max~ \vec{f}_2^\top \vec{v}\\[2mm]
        \hspace{1mm}\text{\normalfont s.t.}~~ 
        \arraycolsep=1.4pt
        \begin{array}[t]{ll}
            \circled{1}   & \mat{A}^\top \vec{x} - \mat{F}_2^\top \vec{v} \ge \vec{0} \\[1mm]
            \circled{2}   & \mat{F}_1\vec{x}                      = \vec{f}_1 \\[1mm]
            \circled{3}   & \vec{x} \ge \vec{0},~\vec{v}~\text{free},
        \end{array} %\\
    \end{array}\mright.
    \hspace{2cm}
    \mathcal{P}_2 : \mleft\lbrace\begin{array}{l}
        \displaystyle\max~ \vec{f}_1^\top \vec{v}\\[2mm]
        \hspace{1mm}\text{\normalfont s.t.}~~ 
        \arraycolsep=1.4pt
        \begin{array}[t]{ll}
            \circled{1}   & -\mat{A} \vec{y} - \mat{F}_1^\top \vec{v} \ge \vec{0} \\[1mm]
            \circled{2}   & \mat{F}_2\vec{y}                      = \vec{f}_2 \\[1mm]
            \circled{3}   & \vec{y} \ge \vec{0},~\vec{v}~\text{free},
        \end{array} %\\
    \end{array}\mright.
\end{equation}
where $\{\vec{x}\in\bbR^{|\Sigma_1|}: \mat{F}_1 \vec{x} = \vec{f}_1, \vec{x}\ge\vec{0}\}$ and $\{\vec{y}\in\bbR^{|\Sigma_2|}: \mat{F}_2 \vec{y} = \vec{f}_2, \vec{y}\ge\vec{0}\}$ are the sequence-form polytopes of the two players, and $\mat{A}$ is the payoff matrix for Player~$1$. Conveniently, the objective values of $\mathcal{P}_1$ and $\mathcal{P}_2$ will be the exact expected utility that each player can secure by playing against a perfectly rational opponent. Since all games are zero sum, the objective values of $\mathcal{P}_1$ and $\mathcal{P}_2$ will sum to $0$ (if they don't, you must have a bug somewhere).


\begin{problem}[20 points]\label{prob:unconstrained strat}
    Implement the linear program for computing Nash equilibrium strategies for both Player~$1$ and Player~$2$.
    
    For each of the three games (rock-paper-superscissors, Kuhn poker, and Leduc poker), and for each of the two player, report Gurobi's output.  
    \hint{make sure to take a look at the ``Gurobi tips and tricks'' at the end of this document. It includes some tips as to how to debug common issues.}
    \hint{start from rock-paper-superscissors, and only then move to the more complex games.}
    \hint{since all games are zero-sum, the objective values of $\mathcal{P}_1$ and $\mathcal{P}_2$ must sum to $0$.}
    \hint{the objective value for $\mathcal{P}_1$ should be $0$ for rock-paper-superscissors, $-0.0555$ for Kuhn poker, and $-0.0856$ for Leduc poker.}
\end{problem}
\begin{solution}
    \todo{Your solution here. You should include six Gurobi outputs (3 games, 2 players per game). Feel free to use the \texttt{verbatim} environment in Latex to simply dump the output. Make sure to specify what game and what player each Gurobi output refers to. Don't forget to include your code at the end of your homework. For example, your output in the case of rock-paper-superscissors for Player~$1$ should look roughly like this}
    \color{violet}\begin{verbatim}
Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (linux64)
Thread count: 8 physical cores, 16 logical processors, using up to 16 threads
Optimize a model with 4 rows, 4 columns and 12 nonzeros
Model fingerprint: 0x5264c0a3
Coefficient statistics:
    Matrix range     [1e+00, 2e+00]
    Objective range  [1e+00, 1e+00]
    Bounds range     [0e+00, 0e+00]
    RHS range        [1e+00, 1e+00]
Presolve removed 1 rows and 0 columns
Presolve time: 0.01s
Presolved: 3 rows, 4 columns, 11 nonzeros

Iteration    Objective       Primal Inf.    Dual Inf.      Time
        0    1.0000000e+00   1.000000e+00   0.000000e+00      0s
        2   -0.0000000e+00   0.000000e+00   0.000000e+00      0s

Solved in 2 iterations and 0.01 seconds
Optimal objective -0.000000000e+00
\end{verbatim}
\end{solution}


\subsection{Computing  optimal deterministic strategies (20 points)}

In this subsection we study how much worse each player is if they (but not the opponent) are restricted to playing deterministic strategies only. To model this, we will add a constraint saying that all entries of the sequence-form strategy vectors $\vec{x}$ and $\vec{y}$ in~\eqref{eq:nash lp} can only take values in $\{0, 1\}$. The resulting \emph{integer} linear programs---which we call $\tilde{\mathcal{P}}_1$ and $\tilde{\mathcal{P}}_2$---are given next.
\begin{equation}\label{eq:deterministic ilp}
    \arraycolsep=1.0pt
    \tilde{\mathcal{P}}_1 : \mleft\lbrace\begin{array}{l}
        \displaystyle\max~ \vec{f}_2^\top \vec{v}\\[2mm]
        \hspace{1mm}\text{\normalfont s.t.}~~ 
        \arraycolsep=1.4pt
        \begin{array}[t]{ll}
            \circled{1}   & \mat{A}^\top \vec{x} - \mat{F}_2^\top \vec{v} \ge \vec{0} \\[1mm]
            \circled{2}   & \mat{F}_1\vec{x}                      = \vec{f}_1 \\[1mm]
            \circled{3}   & \vec{x} \in \{0,1\}^{|\Sigma_1|},~\vec{v}~\text{free},
        \end{array} %\\
    \end{array}\mright.
    \hspace{2cm}
    \tilde{\mathcal{P}}_2 : \mleft\lbrace\begin{array}{l}
        \displaystyle\max~ \vec{f}_1^\top \vec{v}\\[2mm]
        \hspace{1mm}\text{\normalfont s.t.}~~ 
        \arraycolsep=1.4pt
        \begin{array}[t]{ll}
            \circled{1}   & -\mat{A} \vec{y} - \mat{F}_1^\top \vec{v} \ge \vec{0} \\[1mm]
            \circled{2}   & \mat{F}_2\vec{y}                      = \vec{f}_2 \\[1mm]
            \circled{3}   & \vec{y} \in \{0,1\}^{|\Sigma_2|},~\vec{v}~\text{free}.
        \end{array} %\\
    \end{array}\mright.
\end{equation}

\begin{problem}[20 points]\label{prob:deterministic strat}
    Implement the integer linear programs given in~\eqref{eq:deterministic ilp} for computing optimal deterministic strategies for both Player~$1$ and Player~$2$. 
    
    For each of the three games (rock-paper-superscissors, Kuhn poker, and Leduc poker), and for each of the two player, report Gurobi's output. 
    \hint{make sure to take a look at the ``Gurobi tips and tricks'' at the end of this document. It includes some tips as to how to debug common issues.}
    \hint{start from rock-paper-superscissors, and only then move to the more complex games.}
    \hint{here there are \emph{no guarantees} that the value of $\tilde{\mathcal{P}}_1$ and the value of $\tilde{\mathcal{P}}_2$ sum to $0$ anymore! In fact, that will be false in all games.}
\end{problem}
\begin{solution}
    \todo{Your solution here. You should include six Gurobi outputs (3 games, 2 players per game). Feel free to use the \texttt{verbatim} environment in Latex to simply dump the output. Make sure to specify what game and what player each Gurobi output refers to. Don't forget to include your code at the end of your homework. For example, your output in the case of Kuhn poker for Player~$1$ should look roughly like this}
    \color{violet}\begin{verbatim}
Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (linux64)
Thread count: 8 physical cores, 16 logical processors, using up to 16 threads
Optimize a model with 18 rows, 18 columns and 57 nonzeros
Model fingerprint: 0x57532587
Variable types: 6 continuous, 12 integer (12 binary)
Coefficient statistics:
    Matrix range     [2e-01, 1e+00]
    Objective range  [1e+00, 1e+00]
    Bounds range     [1e+00, 1e+00]
    RHS range        [1e+00, 1e+00]
Found heuristic solution: objective -0.3333335
Presolve removed 11 rows and 10 columns
Presolve time: 0.00s
Presolved: 7 rows, 8 columns, 22 nonzeros
Found heuristic solution: objective -0.3333333
Variable types: 0 continuous, 8 integer (5 binary)

Root relaxation: objective -5.555556e-02, 9 iterations, 0.00 seconds

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0   -0.05556    0    3   -0.33333   -0.05556  83.3%     -    0s
H    0     0                      -0.1666667   -0.05556  66.7%     -    0s
     0     0   -0.05556    0    3   -0.16667   -0.05556  66.7%     -    0s

Explored 1 nodes (9 simplex iterations) in 0.00 seconds
Thread count was 16 (of 16 available processors)

Solution count 3: -0.166667 -0.333333 -0.333333
No other solutions better than -0.166667

Optimal solution found (tolerance 1.00e-04)
Best objective -1.666666666667e-01, best bound -1.666666666667e-01, gap 0.0000%
    \end{verbatim}
\end{solution}


\subsection{Controlling the amount of determinism (30 points)}

In \cref{prob:unconstrained strat} no determinism constraint was present. At the other extreme, in \cref{prob:deterministic strat} we insisted that at all decision points a deterministic strategy be followed. In this last subsection we will explore intermediate cases: for each value of $k$, we will study how much value each player can secure if they are constrained to play deterministically in at least $k$ decision points. When $k=0$, we will recover the objective values seen in \cref{prob:unconstrained strat}. When $k$ is equal to the number of decision points of the player in the game, we will recover the objective values seen in \cref{prob:deterministic strat}.

\paragraph{Integer programming model} An optimal strategy for Player~$1$ subject to the constraint that at least $k$ decision points must prescribe a deterministic strategy can be obtained as the solution to the integer linear program $\mathcal{P}_1(k)$ given in~\eqref{eq:controlling ilp pl1}. Understanding the details is not important for this problem, though we included a description of the meaning of each constraint just in case you are curious. 

\begin{equation}\label{eq:controlling ilp pl1}
    \arraycolsep=1.0pt
    \mathcal{P}_1(k) : \mleft\lbrace\begin{array}{l}
        \displaystyle\max~ \vec{f}_2^\top \vec{v}\\[2mm]
        \hspace{1mm}\text{\normalfont s.t.}~~ 
        \arraycolsep=1.4pt
        \begin{array}[t]{lll}
            \circled{1}   & \mat{A}^\top \vec{x} - \mat{F}_2^\top \vec{v} \ge \vec{0} \\[1mm]
            \circled{2}   & \mat{F}_1\vec{x}                      = \vec{f}_1 \\[2mm]
            \circled{3}   & \vec{x}[ja] \ge \vec{z}[ja] & \forall j\in\cJ_1: p_j = \emptyseq,~~a\in A_j\\[4mm]
            \circled{4}   & \vec{x}[ja] \ge \vec{x}[p_j] + \vec{z}[ja] - 1 & \forall j\in\cJ_1: p_j \neq \emptyseq,~~a\in A_j\\[4mm]
            \circled{5}   & \displaystyle\sum_{a\in A_j} \vec{z}[ja] \le 1  & \forall\,j\in\cJ_1\\[4mm]
            \circled{6}   & \displaystyle\sum_{j\in \cJ_1} \sum_{a\in A_j} \vec{z}[ja]\ge k\\[6mm]
            \circled{7}   & \vec{x} \ge \vec{0},~\vec{z}\in\{0,1\}^{|\Sigma_1|},~\vec{v}~\text{free},
        \end{array} %\\
    \end{array}\mright.
\end{equation}
\begin{itemize}
    \item $\vec{z} \in \{0,1\}^{|\Sigma_1|}$ is a binary vector that decides, for each strategy $ja \in \Sigma_1$ of Player~$1$, whether to pick action $a$ at $j$ with probability $1$. Since the strategy vector $\vec{x}$ is expressed in sequence-form, picking action $a$ with probability $1$ at $j$ is expressed through constraints \circled{3} and \circled{4}.
    \item Constraint \circled{5} asserts that no more than one action at each decision point can be forced to be played with probability $1$.
    \item Constraint \circled{6} asserts that in at least $k$ decision point, exactly one of the actions will be forced to be played with probability $1$.
\end{itemize}

The integer linear program $\mathcal{P}_2(k)$ for Player~$2$ is analogous.

\begin{problem}[20 points]
    Implement the integer linear programs $\mathcal{P}_1(k)$ and $\mathcal{P}_2(k)$, described above, for computing optimal strategies with a given lower bound on the amount of determinism. 

    For each of the three games (rock-paper-superscissors, Kuhn poker, and Leduc poker), and for each of the two player $i$, plot the objective value of $\mathcal{P}_i(k)$ as a function of $k \in \{0, \dots, |\cJ_i|\}$ (number of decision points of Player~$i$).
    \hint{make sure to take a look at the ``Gurobi tips and tricks'' at the end of this document. It includes some tips as to how to debug common issues.}
    \hint{Gurobi can be pretty verbose by default. For this problem, if you would like to silence Gurobi you can use \texttt{m.setParam("OutputFlag", 0)}}
    \hint{For Leduc poker, if Gurobi is taking too long to optimize when $k$ is large, you can lower the solution precision by calling \texttt{m.setParam("MIPGap", 0.01)} before \texttt{m.optimize()}. Expect a runtime of up to one-five hours for Leduc poker, depending on how powerful the machine you are using is.}
\end{problem}
\begin{solution}
    \todo{Your solution here. You should include six plots (3 games, 2 players per game). Make sure to specify what game and what player each plot refers to. Don't forget to include your code at the end of your homework.}
\end{solution}

\begin{problem}[10 points]
    Comment on the results you obtained in this problem: do highly-deterministic strategies for the three small games exist? Are the results what you expected? If yes, what did he results confirm? If not, how do you think you can reconcile your previous intuition with the experimental findings?
\end{problem}
\begin{solution}
    \todo{Your solution here}
\end{solution}

\appendix
\section{Appendix: Gurobi tips and tricks}

\paragraph{Basic notation}
Let \texttt{m} denote the Gurobi model object. Then, here is a quick cookbook.
\begin{itemize}
    \item Add a continuous free variable:\newline\verb|m.addVar(-GRB.INFINITY, GRB.INFINITY, vtype=GRB.CONTINUOUS, name="human_var_name_here")|
    \item Add a continuous nonnegative variable:\newline\verb|m.addVar(0.0, GRB.INFINITY, vtype=GRB.CONTINUOUS, name="human_var_name_here")|
    \item Add a binary variable:\newline\verb|m.addVar(0.0, 1.0, vtype=GRB.BINARY, name="human_var_name_here")|
    \item Add an equality constraint:\newline\verb|m.addConstr(lhs == rhs)|
    \item Add an inequality $(\ge)$ constraint:\newline\verb|m.addConstr(lhs >= rhs)|
    \item Set a maximization objective:\newline\verb|m.setObjective(obj, sense=GRB.MAXIMIZE)|
\end{itemize}

\paragraph{Accessing the solution} After calling \verb|m.optimize()|, you can obtain the objective value by calling
\begin{verbatim}
    m.getAttr(GRB.Attr.ObjVal)
\end{verbatim}

If you want to inspect the solution, given a variable object \texttt{v} (the object returned by \texttt{m.addVar}), you can access the value of \texttt{v} in the current solution by calling
\begin{verbatim}
    v.getAttr(GRB.Attr.X)
\end{verbatim}

\paragraph{Troubleshooting} First of all, if you are having a problem with Gurobi, the first thing you should try to do is to ask Gurobi to dump the model that it thinks you are asking to solve to a file in a human readable format. \emph{Reading the model file will be so much easier if you gave names to the variables in your model, using the `\texttt{name}' optional argument of \texttt{addVar}.}

To have Gurobi dump the model, you can use something like this:
\begin{verbatim}
    m.write("/tmp/model.lp")
\end{verbatim}
Of course, you can specify a different path. However, it is important that you keep the `\texttt{.lp}' extension: there are multiple format that Gurobi can output, and it uses the file extension to guess which format you want.

Beyond the general rule of thumb above, make sure of the following:
\begin{itemize}
    \item Start from rock-paper-superscissors. There, the \verb|/tmp/model.lp| file for Player 1 for \cref{prob:unconstrained strat} should look something like this (probably with different variable names):
\begin{verbatim}
\ Model game_value_pl1
\ LP format - for model browsing. Use MPS format to capture full model detail.
Maximize
    v[d1_pl2]
Subject To
    R0: x[('d1_pl1',_'p')] - x[('d1_pl1',_'s')] - v[d1_pl2] >= 0
    R1: - x[('d1_pl1',_'r')] + 2 x[('d1_pl1',_'s')] - v[d1_pl2] >= 0
    R2: x[('d1_pl1',_'r')] - 2 x[('d1_pl1',_'p')] - v[d1_pl2] >= 0
    R3: x[('d1_pl1',_'r')] + x[('d1_pl1',_'p')] + x[('d1_pl1',_'s')] = 1
Bounds
    v[d1_pl2] free
End    
\end{verbatim}
    \emph{Note:} Gurobi omits listing nonnegative variables in the \verb|Bounds| section.
    \item Did you remember to specify that you want a \emph{maximization} problem? (Gurobi's default is minimization) If Gurobi says that the model is unbounded, chances are you forgot.
    \item Check that the number of variables and constraints is what you expect. Are the sense of the constraints (equality, $\le$, $\ge$) what you wanted?
\end{itemize}

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}
